{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RandomForest.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Tiagosf00/ml-kaggle/blob/master/ml/class/RandomForest.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qxGUUE01FY2J",
        "colab_type": "text"
      },
      "source": [
        "###Random Forest\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SItr6VjqQJ2T",
        "colab_type": "text"
      },
      "source": [
        "[Random Forest](\"https://en.wikipedia.org/wiki/Random_forest\") é um tipo de algoritimo de classificação ou regreção, ou seja seu objetivo é predizer a classe a que um dado pertençe. E como o nome pode intuir ele usa uma floresta, no caso de arvores de decisão, que já foram esplicadas anteriormente, que são usadas para chegar ao resultado.\n",
        "\n",
        "Essa random forest é uma tecnica de [conjunto](\"https://en.wikipedia.org/wiki/Ensemble_learning\"), ou seja ela usa multiplos modelos preditivos menores, no caso arvores de decisão e a partir de suas multiplas predições a floresta estabelece a sua predição final.\n",
        "\n",
        "E com essa formação, podemos ter uma predição mais precisa pois assim os erros de uma arvore podem ser corrigidos pelo resto da floresta.\n",
        "\n",
        " "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3w-HkrFpNObD",
        "colab_type": "text"
      },
      "source": [
        "![Árvores Aleatórias](RF.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Sp2xSLDeHYX",
        "colab_type": "text"
      },
      "source": [
        "Para criarmos uma Random Forest temos que treinar cada arvore individualmente para enfim fazermos a floresta funcionar, que é o objetivo do algoritimo, ter varios votos com viezes diferentes para juntos termos o melhor resultado. \n",
        "\n",
        "Para treinarmos cada uma das arvores, precisamos realizar o [Bagging](\"https://en.wikipedia.org/wiki/Bootstrap_aggregating\"), ou Bootstrap, que um processo de seleção de casos de treinamento, não todos, que são usados para para treinar cada arvore individualmente.\n",
        "\n",
        "O resultado dado pela floresta pode ser a predição mais predita entre as arvores ou a media das predições:\n",
        "\n",
        "$\\hat{f} = \\frac{1}{B}\\sum_{b=1}^{B} f_b (x')$\n",
        "\n",
        "Podemos tambem estimar a incerteza da predição apartir da formula:\n",
        "\n",
        "$\\sigma = \\sqrt{\\frac{\\sum_{b=1}^{B}(f_b(x')-f)^2}{B-1}}\\$\n",
        "\n",
        "Abaixo temos um exemplo de um pseudoalgoritimo de uma random forest, em que n é menor que o total de exemplos, X são os atributos, Y sãos rotulos e f sãos as arvores a serem criadas."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZdYf4Ii3P89K",
        "colab_type": "text"
      },
      "source": [
        "![Algoritmo](Algo.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GImDEeZaQJth",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "#RandomForestClassifier(n_estimators=100, criterion='gini', max_depth=None, max_leaf_nodes=None, min_impurity_decrease=0.0, bootstrap=True, oob_score=False, random_state=None, max_samples=None)\n",
        "A seguir será mostrado como utilizar o código do skitlearn ela recebe diversos parâmetros para o algoritmo de predição vamos começar mostrando os principais parâmetros:\n",
        "\n",
        "#n_estimators\n",
        "Esse parâmetro indica a quantidade de arvores a ser efetuadas pelo programa caso não coloque esse parâmetro ele utiliza 100 arvores.\n",
        "\n",
        "#criterion \n",
        "Esse parâmetro e uma string com o nome do critério utilizado para calcular a impureza e os valores possíveis são “gini” e “entropy” que representam um índice de desigualdade e a entropia.\n",
        "\n",
        "#max_depth\n",
        "Define a profundidade máxima da arvore, facilitando diminuir a complexidade e custo de utilizar a arvore, além de reduzir o superajustamento.\n",
        "\n",
        "#max_leaf_nodes\n",
        "Define a quantidade máxima de nós na arvore, ou seja, limita a quantidade de divisões que a arvore pode fazer, sendo uma maneira mais precisa de impedir superajustamento que a max_depht \n",
        "\n",
        "#min_impurity_decrease\n",
        "Essa variável define o valor mínimo de impureza que a transformação de uma folha em nó deve reduzir para ocorrer a divisão\n",
        "\n",
        "#bootstrap\n",
        "Essa variável define se ocorre o bagging ou não se ela for false todas as arvores são treinadas com o conjunto de treino inteiro\n",
        "\n",
        "#oob_score\n",
        "Essa variável define se o programa deve, antes de fazer o bagging, separar o conjunto de teste para avaliar o modelo do conjunto utilizado para criar as arvores\n",
        "#random_state\n",
        "Permite a repetibilidade do processo pois quando em NONE ele vai gerar um valor aleatório que será utilizado de semente para a execução dos fatores aleatórios do programa, mas se um número for colocado e for utilizado o mesmo data set e possível repetir o resultado desde que se saiba o número.\n",
        "\n",
        "#max_samples\n",
        "Define o número máximo de exemplos a ser lido por cada estimador se o bootstrap for igual true, ou seja, o número máximo de exemplos em cada “bag”.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8M-XKELAQJfc",
        "colab_type": "text"
      },
      "source": [
        "# Aplicação\n",
        "\n",
        "O hospital Albert Einstein, em São Paulo, disponibilizou uma [base de dados](https://www.kaggle.com/einsteindata4u/covid19) de pacientes anônimos que fizeram o teste para o COVID-19, a base possui diversos dados clínicos (atributos) dos pacientes junto ao resultado dos testes feitos.\n",
        "\n",
        "Para demonstrar o uso do algoritmo de classificação Random Forest em um problema real, a base do COVID-19 foi utilizada para treinar um classificador utilizando a implementação do algoritmo disponível na biblioteca sklearn. O classificador possui o intuito de prever a condição de pacientes com a doença utilizando sinais e sintomas."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0cJBc0kqGvdf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import metrics"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aTy1qK9xGwVL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Importando o dataset do Covid-19\n",
        "data = pd.read_excel('dataset.xlsx')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cuucma2_Hw11",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Dados clínicos selecionados\n",
        "X = data[['Patient age quantile',\n",
        "          'Patient addmited to regular ward (1=yes, 0=no)',\n",
        "          'Patient addmited to semi-intensive unit (1=yes, 0=no)',\n",
        "          'Patient addmited to intensive care unit (1=yes, 0=no)']]\n",
        "\n",
        "# Resultado do Exame\n",
        "y = data['SARS-Cov-2 exam result']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8fkeF5aeIaM7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 70% para treinamento e 30% para teste\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P2WwpsDgIaBC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "classificador = RandomForestClassifier(n_estimators=100)\n",
        "\n",
        "classificador.fit(X_train, y_train)\n",
        "\n",
        "y_pred = classificador.predict(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MMB4xfTsIZvu",
        "colab_type": "code",
        "outputId": "173fed0e-ba86-4bc5-9ed9-05fe5ce2a67b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "acuracia = metrics.accuracy_score(y_test, y_pred)*100\n",
        "\n",
        "print(\"Acurácia do classificador: {0:.2f}%\".format(acuracia))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Acurácia do classificador: 90.02%\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}