{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qxGUUE01FY2J"
   },
   "source": [
    "# Random Forest\n",
    "\n",
    "[Random Forest](\"https://en.wikipedia.org/wiki/Random_forest\") é um tipo de algoritimo de classificação ou regreção, ou seja seu objetivo é predizer a classe a que um dado pertençe. E como o nome pode intuir ele usa uma floresta, no caso uma floresta de arvores de decisão, que já foram esplicadas anteriormente. Essas arvores são usadas para chegar ao resultado final do conjunto.\n",
    "\n",
    "Essa random forest é uma tecnica de [conjunto](\"https://en.wikipedia.org/wiki/Ensemble_learning\"), ou seja ela usa multiplos modelos preditivos menores, no caso arvores de decisão e a partir de suas multiplas predições a floresta estabelece a sua predição final.\n",
    "\n",
    "E com essa formação, podemos ter uma predição mais precisa pois assim os erros de uma arvore podem ser corrigidos pelo resto da floresta.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3w-HkrFpNObD"
   },
   "source": [
    "![Árvores Aleatórias](RF.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_Sp2xSLDeHYX"
   },
   "source": [
    "Para criarmos uma [Random Forest](\"https://medium.com/machina-sapiens/o-algoritmo-da-floresta-aleat%C3%B3ria-3545f6babdf8\") temos que treinar cada arvore individualmente para enfim fazermos a floresta funcionar, que é o objetivo do algoritimo, ter varios votos com viezes diferentes para juntos termos o melhor resultado. \n",
    "\n",
    "Para treinarmos cada uma das arvores, precisamos realizar o [Bagging](\"https://en.wikipedia.org/wiki/Bootstrap_aggregating\"), ou Bootstrap, que um processo de seleção de casos de treinamento, que são usados para para treinar cada arvore individualmente.\n",
    "\n",
    "O resultado dado pela floresta pode ser a predição mais predita entre as arvores ou a media das predições:\n",
    "\n",
    "$\\hat{f} = \\frac{1}{B}\\sum_{b=1}^{B} f_b (x')$\n",
    "\n",
    "Podemos tambem estimar a incerteza da predição apartir da formula:\n",
    "\n",
    "$\\sigma = \\sqrt{\\frac{\\sum_{b=1}^{B}(f_b(x')-f)^2}{B-1}}$\n",
    "\n",
    "Abaixo temos um exemplo de um pseudoalgoritimo de uma random forest, em que n é menor que o total de exemplos, X são os atributos, Y sãos rotulos e f sãos as arvores a serem criadas. A primeirla linha estabelece os cojundos de dados. A segunda linha cria um laço de repetição que iráá criar as arvores da floresta, criando um bag, e apartir dele treinando uma arvore f nele. Depois estabelece o resultado final a partir da floresta toda. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZdYf4Ii3P89K"
   },
   "source": [
    "![Algoritmo](Algo.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GImDEeZaQJth"
   },
   "source": [
    "# Implementação\n",
    "\n",
    "## Parâmetros\n",
    "\n",
    "A seguir será mostrado como utilizar o código do skitlearn ela recebe diversos parâmetros para o algoritmo de predição vamos começar mostrando os principais parâmetros.\n",
    "\n",
    "\n",
    "### n_estimators\n",
    "Esse parâmetro indica a quantidade de arvores a ser efetuadas pelo programa caso não coloque esse parâmetro ele utiliza 100 arvores.\n",
    "\n",
    "### criterion \n",
    "Esse parâmetro é uma string com o nome do critério utilizado para calcular a impureza. Seus comandos possíveis são “gini” e “entropy” que representam um índice de desigualdade e a entropia.\n",
    "\n",
    "### max_depth\n",
    "Define a profundidade máxima da arvore, facilitando diminuir a complexidade e custo de utilizar a arvore, além de reduzir o superajustamento.\n",
    "\n",
    "### max_leaf_nodes\n",
    "Define a quantidade máxima de nós na arvore, ou seja, limita a quantidade de divisões que a arvore pode fazer, sendo uma maneira mais precisa de impedir superajustamento que a max_depht e tambem de diminiur o custo operacional.\n",
    "\n",
    "### min_impurity_decrease\n",
    "Essa variável define o valor mínimo de impureza que a transformação de uma folha em nó deve reduzir para ocorrer a divisão.\n",
    "\n",
    "### bootstrap\n",
    "Essa variável define se ocorre o bagging ou não se ela for false todas as arvores são treinadas com o conjunto de treino inteiro.\n",
    "\n",
    "### oob_score\n",
    "Essa variável define se o programa deve, antes de fazer o bagging, separar o conjunto de teste para avaliar o modelo do conjunto utilizado para criar as arvores.\n",
    "\n",
    "### random_state\n",
    "Permite a repetibilidade do processo pois quando em NONE ele vai gerar um valor aleatório que será utilizado de semente para a execução dos fatores aleatórios do programa, mas se um número for colocado e for utilizado o mesmo data set e possível repetir o resultado desde que se saiba o número.\n",
    "\n",
    "### max_samples\n",
    "Define o número máximo de exemplos a ser lido por cada estimador se o bootstrap for igual true, ou seja, o número máximo de exemplos em cada “bag”."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Métodos\n",
    "\n",
    "Agora que já vimos os parâmetros vamos agora mostrar como utilizar a random forest do skitlearn\n",
    "\n",
    "\n",
    "### apply(X)\n",
    "Essa função permite receber separadamente para cada elemento de X as predições de cada uma das arvores na floresta em um formato de matriz (quantidade de elementos em X, quantidade de arvores)\n",
    "### fit(X, y)\n",
    "Essa e a função de treinamento do algoritmo que recebe os atributos preditivos e os rótulos do conjunto de treinamento.\n",
    "### predict(X)\n",
    "Essa e a função de utilizar o classificador para predizer a classe de cada termo da entrada e retorna um vetor com cada predição de rotulo.\n",
    "\n",
    "### predict_proba(X)\n",
    "Parecida com a predict a predict_proba utiliza o estimador para predizer o rotulo de cada termo da entrada, porem diferentemente do predict que retorna um vetor com cada rotulo ele retorna uma matriz com a probabilidade de ser cada classe.\n",
    "\n",
    "### score(X, y)\n",
    "Essa e a função fornecida pela random forest do skitlearn que permite uma auto avaliação do programa e retorna a acurácia media do processo de predição.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8M-XKELAQJfc"
   },
   "source": [
    "# Aplicação\n",
    "\n",
    "O hospital Albert Einstein, em São Paulo, disponibilizou uma [base de dados](https://www.kaggle.com/einsteindata4u/covid19) de pacientes anônimos que fizeram o teste para o COVID-19, a base possui diversos dados clínicos dos pacientes junto ao resultado dos testes feitos.\n",
    "\n",
    "Para demonstrar o uso do algoritmo de classificação Random Forest em um problema real, a base do COVID-19 foi utilizada para treinar um classificador utilizando a implementação do algoritmo disponível na biblioteca sklearn. O classificador possui o intuito de prever a condição de pacientes com a doença utilizando seus dados clínicos como sinais, sintomas, entre outras informações."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0cJBc0kqGvdf"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aTy1qK9xGwVL"
   },
   "outputs": [],
   "source": [
    "# Importando o dataset do Covid-19\n",
    "data = pd.read_excel('dataset.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TdL4GWhlcv0x"
   },
   "source": [
    "Separamos o rótulo e os atributos preditivos a serem considerados pelo classificador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Cuucma2_Hw11"
   },
   "outputs": [],
   "source": [
    "# Dados clínicos selecionados\n",
    "X = data[['Patient age quantile',\n",
    "          'Patient addmited to regular ward (1=yes, 0=no)',\n",
    "          'Patient addmited to semi-intensive unit (1=yes, 0=no)',\n",
    "          'Patient addmited to intensive care unit (1=yes, 0=no)']]\n",
    "\n",
    "# Resultado do Exame\n",
    "y = data['SARS-Cov-2 exam result']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pIN4Vz5-cyD7"
   },
   "source": [
    "Para treinar e testar o classificador, dividimos a base de dados em duas, uma com 70% dos pacientes para treinamento, e outra com 30% dos pacientes para testar a acurácia do modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8fkeF5aeIaM7"
   },
   "outputs": [],
   "source": [
    "# 70% para treinamento e 30% para teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mwoFXS3Nc0vu"
   },
   "source": [
    "Para gerar o classificador utilizamos o `RandomForestClassifier` da biblioteca sklearn, e alguns parâmetros descritos abaixo:\n",
    "\n",
    "* n_estimators = 100;\n",
    "* Adicionar outros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "P2WwpsDgIaBC"
   },
   "outputs": [],
   "source": [
    "classificador = RandomForestClassifier(n_estimators=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OGgFIL6jdAII"
   },
   "source": [
    "Com o método `fit` treinamos o classificador com os elementos de treino, e utilizamos o método `predict` para predizer os resultados dos elementos de teste, utilizando do classificador treinado:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0jVTEK9Zc_Xo"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['negative' 'negative' 'negative' ... 'positive' 'negative' 'negative']\n"
     ]
    }
   ],
   "source": [
    "classificador.fit(X_train, y_train)\n",
    "\n",
    "y_pred = classificador.predict(X_test)\n",
    "\n",
    "# Resultados obtidos pelo classificador\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "É possível visualizar a predição de cada uma dar árvores utilizando a função `apply`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139
    },
    "colab_type": "code",
    "id": "3uASMsNMYBSI",
    "outputId": "6ca935ae-99d5-4eab-f997-5eb4a70be199"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[33, 41, 22, ..., 25, 25, 38],\n",
       "       [63, 50, 37, ..., 39, 39, 48],\n",
       "       [63, 50, 37, ..., 39, 39, 48],\n",
       "       ...,\n",
       "       [93, 89, 45, ..., 54, 59, 63],\n",
       "       [62, 49, 36, ..., 37, 38, 47],\n",
       "       [46, 42, 26, ..., 30, 29, 40]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classificador.apply(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fxZacdF_dFR6"
   },
   "source": [
    "Comparando os resultados obtidos com os de teste, podemos calcular a acurácia do classificador utilizando a função `score`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "MMB4xfTsIZvu",
    "outputId": "055195c8-79c1-4b5f-b066-5588800f9400"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia do classificador: 89.79%\n"
     ]
    }
   ],
   "source": [
    "acuracia = classificador.score(X_test, y_test)*100\n",
    "\n",
    "print(\"Acurácia do classificador: {0:.2f}%\".format(acuracia))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "RandomForest.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
