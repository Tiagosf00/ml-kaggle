{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RandomForest.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qxGUUE01FY2J",
        "colab_type": "text"
      },
      "source": [
        "# Random Forest\n",
        "\n",
        "\n",
        "\n",
        "vamos colocar a ordem de como faremos aqui?\n",
        "\n",
        "dataset utilizado:\n",
        "\n",
        "explicar a ideia do algoritimo\n",
        "\n",
        "explicar o algoritimo\n",
        "\n",
        "esplicar a implementação dele no skitlearn que vamo usar(https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html)\n",
        "\n",
        "e trabalhar com ele(dataset do covid-19 https://www.kaggle.com/einsteindata4u/covid19)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SItr6VjqQJ2T",
        "colab_type": "text"
      },
      "source": [
        "[Random Forest](\"https://en.wikipedia.org/wiki/Random_forest\") é um tipo de algoritimo de classificação ou regreção, ou seja seu objetivo é predizer a classe a que um dado pertençe. E como o nome pode intuir ele usa uma floresta, no caso uma floresta de arvores de decisão, que já foram esplicadas anteriormente. Essas arvores são usadas para chegar ao resultado final do conjunto.\n",
        "\n",
        "Essa random forest é uma tecnica de [conjunto](\"https://en.wikipedia.org/wiki/Ensemble_learning\"), ou seja ela usa multiplos modelos preditivos menores, no caso arvores de decisão e a partir de suas multiplas predições a floresta estabelece a sua predição final.\n",
        "\n",
        "E com essa formação, podemos ter uma predição mais precisa pois assim os erros de uma arvore podem ser corrigidos pelo resto da floresta.\n",
        "\n",
        " "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3w-HkrFpNObD",
        "colab_type": "text"
      },
      "source": [
        "![Árvores Aleatórias](RF.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Sp2xSLDeHYX",
        "colab_type": "text"
      },
      "source": [
        "Para criarmos uma [Random Forest](\"https://medium.com/machina-sapiens/o-algoritmo-da-floresta-aleat%C3%B3ria-3545f6babdf8\") temos que treinar cada arvore individualmente para enfim fazermos a floresta funcionar, que é o objetivo do algoritimo, ter varios votos com viezes diferentes para juntos termos o melhor resultado. \n",
        "\n",
        "Para treinarmos cada uma das arvores, precisamos realizar o [Bagging](\"https://en.wikipedia.org/wiki/Bootstrap_aggregating\"), ou Bootstrap, que um processo de seleção de casos de treinamento, que são usados para para treinar cada arvore individualmente.\n",
        "\n",
        "O resultado dado pela floresta pode ser a predição mais predita entre as arvores ou a media das predições:\n",
        "\n",
        "$\\hat{f} = \\frac{1}{B}\\sum_{b=1}^{B} f_b (x')$\n",
        "\n",
        "Podemos tambem estimar a incerteza da predição apartir da formula:\n",
        "\n",
        "$\\sigma = \\sqrt{\\frac{\\sum_{b=1}^{B}(f_b(x')-f)^2}{B-1}}$\n",
        "\n",
        "Abaixo temos um exemplo de um pseudoalgoritimo de uma random forest, em que n é menor que o total de exemplos, X são os atributos, Y sãos rotulos e f sãos as arvores a serem criadas. A primeirla linha estabelece os cojundos de dados. A segunda linha cria um laço de repetição que iráá criar as arvores da floresta, criando um bag, e apartir dele treinando uma arvore f nele. Depois estabelece o resultado final a partir da floresta toda. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZdYf4Ii3P89K",
        "colab_type": "text"
      },
      "source": [
        "![Algoritmo](Algo.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GImDEeZaQJth",
        "colab_type": "text"
      },
      "source": [
        "#Implementação\n",
        "###RandomForestClassifier(n_estimators=100, criterion='gini', max_depth=None, max_leaf_nodes=None, min_impurity_decrease=0.0, bootstrap=True, oob_score=False, random_state=None, max_samples=None)\n",
        "A seguir será mostrado como utilizar o código do skitlearn ela recebe diversos parâmetros para o algoritmo de predição vamos começar mostrando os principais parâmetros:\n",
        "\n",
        "##n_estimators\n",
        "Esse parâmetro indica a quantidade de arvores a ser efetuadas pelo programa caso não coloque esse parâmetro ele utiliza 100 arvores.\n",
        "\n",
        "##criterion \n",
        "Esse parâmetro é uma string com o nome do critério utilizado para calcular a impureza. Seus comandos possíveis são “gini” e “entropy” que representam um índice de desigualdade e a entropia.\n",
        "\n",
        "#max_depth\n",
        "Define a profundidade máxima da arvore, facilitando diminuir a complexidade e custo de utilizar a arvore, além de reduzir o superajustamento.\n",
        "\n",
        "#max_leaf_nodes\n",
        "Define a quantidade máxima de nós na arvore, ou seja, limita a quantidade de divisões que a arvore pode fazer, sendo uma maneira mais precisa de impedir superajustamento que a max_depht e tambem de diminiur o custo operacional.\n",
        "\n",
        "#min_impurity_decrease\n",
        "Essa variável define o valor mínimo de impureza que a transformação de uma folha em nó deve reduzir para ocorrer a divisão.\n",
        "\n",
        "#bootstrap\n",
        "Essa variável define se ocorre o bagging ou não se ela for false todas as arvores são treinadas com o conjunto de treino inteiro.\n",
        "\n",
        "#oob_score\n",
        "Essa variável define se o programa deve, antes de fazer o bagging, separar o conjunto de teste para avaliar o modelo do conjunto utilizado para criar as arvores.\n",
        "#random_state\n",
        "Permite a repetibilidade do processo pois quando em NONE ele vai gerar um valor aleatório que será utilizado de semente para a execução dos fatores aleatórios do programa, mas se um número for colocado e for utilizado o mesmo data set e possível repetir o resultado desde que se saiba o número.\n",
        "\n",
        "#max_samples\n",
        "Define o número máximo de exemplos a ser lido por cada estimador se o bootstrap for igual true, ou seja, o número máximo de exemplos em cada “bag”.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8M-XKELAQJfc",
        "colab_type": "text"
      },
      "source": [
        "# Aplicação\n",
        "\n",
        "O hospital Albert Einstein, em São Paulo, disponibilizou uma [base de dados](https://www.kaggle.com/einsteindata4u/covid19) de pacientes anônimos que fizeram o teste para o COVID-19, a base possui diversos dados clínicos (atributos) dos pacientes junto ao resultado dos testes feitos.\n",
        "\n",
        "Para demonstrar o uso do algoritmo de classificação Random Forest em um problema real, a base do COVID-19 foi utilizada para treinar um classificador utilizando a implementação do algoritmo disponível na biblioteca sklearn. O classificador possui o intuito de prever a condição de pacientes com a doença utilizando sinais e sintomas."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0cJBc0kqGvdf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import metrics"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aTy1qK9xGwVL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Importando o dataset do Covid-19\n",
        "data = pd.read_excel('dataset.xlsx')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TdL4GWhlcv0x",
        "colab_type": "text"
      },
      "source": [
        "Separamos o rótulo e os atributos preditivos a serem considerados pelo classificador."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cuucma2_Hw11",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Dados clínicos selecionados\n",
        "X = data[['Patient age quantile',\n",
        "          'Patient addmited to regular ward (1=yes, 0=no)',\n",
        "          'Patient addmited to semi-intensive unit (1=yes, 0=no)',\n",
        "          'Patient addmited to intensive care unit (1=yes, 0=no)']]\n",
        "\n",
        "# Resultado do Exame\n",
        "y = data['SARS-Cov-2 exam result']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pIN4Vz5-cyD7",
        "colab_type": "text"
      },
      "source": [
        "Para treinar e testar o classificador, dividimos a base de dados em duas, uma com 70% dos pacientes para treinamento, e outra com 30% dos pacientes para testar a acurácia do modelo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8fkeF5aeIaM7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 70% para treinamento e 30% para teste\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mwoFXS3Nc0vu",
        "colab_type": "text"
      },
      "source": [
        "Para gerar o classificador utilizamos o `RandomForestClassifier` da biblioteca sklearn, e alguns parâmetros descritos abaixo:\n",
        "\n",
        "* n_estimators = 100;\n",
        "* Adicionar outros"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P2WwpsDgIaBC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "classificador = RandomForestClassifier(n_estimators=100)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OGgFIL6jdAII",
        "colab_type": "text"
      },
      "source": [
        "Com o método `fit` treinamos o classificador com os elementos de treino, e utilizamos o método `predict` para predizer os resultados dos elementos de teste, utilizando do classificador treinado:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0jVTEK9Zc_Xo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "classificador.fit(X_train, y_train)\n",
        "\n",
        "y_pred = classificador.predict(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fxZacdF_dFR6",
        "colab_type": "text"
      },
      "source": [
        "Comparando os resultados obtidos com os de teste, podemos calcular a acurácia do classificador:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MMB4xfTsIZvu",
        "colab_type": "code",
        "outputId": "173fed0e-ba86-4bc5-9ed9-05fe5ce2a67b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "acuracia = metrics.accuracy_score(y_test, y_pred)*100\n",
        "\n",
        "print(\"Acurácia do classificador: {0:.2f}%\".format(acuracia))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Acurácia do classificador: 90.02%\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}